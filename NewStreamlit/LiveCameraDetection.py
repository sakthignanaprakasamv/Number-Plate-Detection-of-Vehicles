import streamlit as st
from streamlit_webrtc import webrtc_streamer, VideoProcessorBase, WebRtcMode
import av
import cv2
import numpy as np
from ultralytics import YOLO
import easyocr
import re

# ---------------- PAGE CONFIG ----------------
st.set_page_config(page_title="Live Camera Detection", layout="wide")
st.title("ðŸ“· Live Camera Detection")

st.markdown(
    "Real-time number plate detection using live camera feed with OCR output.",
)

# ---------------- LOAD MODEL ----------------
@st.cache_resource
def load_model():
    return YOLO("runs/exp/weights/best.pt")  # âœ… YOUR MODEL PATH

@st.cache_resource
def load_ocr():
    return easyocr.Reader(['en'], gpu=False)

model = load_model()
ocr_reader = load_ocr()

# ---------------- USER CONTROLS ----------------
confidence = st.slider(
    "Confidence Threshold",
    min_value=0.10,
    max_value=0.90,
    value=0.40,
    step=0.05
)

st.markdown(f"**Selected Threshold:** `{confidence:.2f}`")

# ---------------- VIDEO PROCESSOR ----------------
class VideoProcessor(VideoProcessorBase):
    def recv(self, frame):
        img = frame.to_ndarray(format="bgr24")

        results = model.predict(
            source=img,
            conf=confidence,
            imgsz=640,
            verbose=False
        )

        for box in results[0].boxes:
            x1, y1, x2, y2 = map(int, box.xyxy[0])
            conf_score = float(box.conf[0])

            plate_crop = img[y1:y2, x1:x2]
            ocr_text = ""

            if plate_crop.size != 0:
                ocr_result = ocr_reader.readtext(
                    plate_crop,
                    allowlist="ABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789",
                    detail=0
                )
                if ocr_result:
                    ocr_text = re.sub(r'[^A-Z0-9]', '', ocr_result[0])

            # ---- Draw thick bounding box ----
            cv2.rectangle(
                img,
                (x1, y1),
                (x2, y2),
                (0, 255, 0),
                3
            )

            # ---- Label (OCR + confidence only) ----
            label = f"{ocr_text} ({conf_score:.2f})" if ocr_text else f"({conf_score:.2f})"

            cv2.putText(
                img,
                label,
                (x1, max(y1 - 10, 25)),
                cv2.FONT_HERSHEY_SIMPLEX,
                0.7,
                (0, 255, 0),
                2
            )

        return av.VideoFrame.from_ndarray(img, format="bgr24")

# ---------------- WEBRTC STREAM ----------------
webrtc_streamer(
    key="live-camera-detection",
    mode=WebRtcMode.SENDRECV,
    video_processor_factory=VideoProcessor,
    media_stream_constraints={"video": True, "audio": False},
)

# ---------------- FOOTER NOTE ----------------
st.divider()
st.markdown(
    "<p style='text-align:center;color:gray;'>Live Camera Detection â€¢ YOLO + OCR</p>",
    unsafe_allow_html=True
)
